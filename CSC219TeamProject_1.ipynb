{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srujayreddyv/CSC219-P1-HeartDiseaseDetection/blob/main/CSC219TeamProject_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkymLoID40uy"
      },
      "source": [
        "## CSC 219- Machine Learning (Fall 2023)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EnXlEp4M6xS"
      },
      "source": [
        "# PROJECT: 1 Heart Disease Detection using Neural Networks\n",
        "### Team Challengers:\n",
        "### 1. Alekya Paladugu\n",
        "### 2. Samah Eltayeb\n",
        "### 3. Srujay Reddy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB0Wg35XRpfT"
      },
      "source": [
        "# 1. 0 UPLOADING THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwasYxjI7gGO"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T20lTqI4RtVL"
      },
      "source": [
        "# 2.0 IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyJWwlV13MoK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import scipy as sp\n",
        "from scipy.stats import zscore\n",
        "\n",
        "import sklearn as sk\n",
        "import tensorflow as tf\n",
        "%load_ext tensorboard\n",
        "\n",
        "import io\n",
        "import os\n",
        "import sys\n",
        "import requests\n",
        "import datetime\n",
        "import shutil\n",
        "from collections.abc import Sequence\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib as pltLib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn.feature_extraction.text as sk_text\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# Set random seed for TensorFlow\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Set random seed for NumPy\n",
        "np.random.seed(42)\n",
        "\n",
        "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    # find out the type of the target column.\n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
        "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G8uPuhJRxKQ"
      },
      "source": [
        "# 3.0 UNDERSTANDING THE DATA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rvL8qteO75d"
      },
      "source": [
        "## 3.1 READING THE DATASET  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB08muVd8KD4"
      },
      "outputs": [],
      "source": [
        "Dataset_CSV = 'heart_statlog_cleveland_hungary_final.csv'\n",
        "\n",
        "df= pd.read_csv(Dataset_CSV, delimiter =\",\", na_values=['NA','?'])\n",
        "df[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SNQG61ykLSn"
      },
      "source": [
        "## 3.2 CHECKING FOR NULL VALUES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vmzSLbNvQG2"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OfRdcukkQH_"
      },
      "source": [
        "## 3.3 CHECKING AND REMOVING DUPLICATE VALUES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pSGjWMHnx-H"
      },
      "outputs": [],
      "source": [
        "df.duplicated().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOi-XIgEoOuy"
      },
      "outputs": [],
      "source": [
        "dups = df.duplicated()\n",
        "\n",
        "print('Number of duplicate rows = %d' % (dups.sum()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XIAtat0uFhZ"
      },
      "outputs": [],
      "source": [
        "df_Dups = df.copy()\n",
        "df_Dups['is_duplicated'] = df_Dups.duplicated(keep='first')\n",
        "count_dups = df_Dups['is_duplicated'].value_counts().reset_index()\n",
        "count_dups.columns = ['col', 'count']\n",
        "print(count_dups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCWxGcfWtwy-"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpnH0hsqT_hF"
      },
      "source": [
        "# 4.0 DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzqC40UnUi9C"
      },
      "source": [
        "## 4.1 NORMALIZING NUMERIC FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encode_text_dummy(df, 'sex')\n",
        "encode_text_dummy(df, 'chest pain type')\n",
        "encode_text_dummy(df, 'fasting blood sugar')\n",
        "encode_text_dummy(df, 'resting ecg')\n",
        "encode_text_dummy(df, 'exercise angina')\n",
        "encode_text_dummy(df, 'ST slope')\n",
        "#encode_text_dummy(df, 'target')"
      ],
      "metadata": {
        "id": "7pJohg5x2tGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrToymdwVdlG"
      },
      "outputs": [],
      "source": [
        "x=df.drop([\"target\"],axis=1)\n",
        "y=df.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA386FtFQUts"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKapXDL6ubIT"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5nXNbcCUWJM"
      },
      "outputs": [],
      "source": [
        "xn1 = zscore(x)\n",
        "xn1.shape\n",
        "xn1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo-PByl0WD1R"
      },
      "outputs": [],
      "source": [
        "x1_numpy = xn1.to_numpy()\n",
        "y1_numpy = y.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR3XGTsqygoz"
      },
      "outputs": [],
      "source": [
        "y1_numpy.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qv-YZxCXMnp"
      },
      "source": [
        "## 4.2 TRAIN/TEST SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmvuCUsfXLvI"
      },
      "outputs": [],
      "source": [
        "x1_train, x1_test, y1_train, y1_test = train_test_split(x1_numpy, y1_numpy, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy0zCa3yREaY"
      },
      "source": [
        "# 5.0 BUILDING MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGGVGR1ZZXaW"
      },
      "source": [
        "## 5.1 NEAREST NEIGHBOR (NN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCzubl4Tc3eI"
      },
      "outputs": [],
      "source": [
        "k = 5\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_classifier.fit(x1_train, y1_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y1_pred_knn = knn_classifier.predict(x1_test)\n",
        "\n",
        "# Display classification report for k-NN\n",
        "classification_rep1_knn = classification_report(y1_test, y1_pred_knn)\n",
        "print(\"Classification Report for k-NN (5):\")\n",
        "print(classification_rep1_knn)\n",
        "\n",
        "# Plot confusion matrix for k-NN\n",
        "confusion1_knn = confusion_matrix(y1_test, y1_pred_knn)\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Confusion Matrix for k-NN (5)\")\n",
        "sns.heatmap(confusion1_knn, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "#Plot roc\n",
        "fprn, tprn, thresholds = roc_curve(y1_test,y1_pred_knn)\n",
        "roc_auc = auc(fprn, tprn)\n",
        "plt.figure()\n",
        "plt.plot(fprn, tprn, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "#plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWPdoKHdf8yM"
      },
      "source": [
        "## 5.2 SUPPORT VECTOR MACHINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQJRjjqWpREE"
      },
      "outputs": [],
      "source": [
        "svm_Model = SVC(kernel='poly')\n",
        "svm_Model.fit(x1_train, y1_train)\n",
        "y1_pred_svm = svm_Model.predict(x1_test)\n",
        "\n",
        "classification_rep1_svm = classification_report(y1_test, y1_pred_svm)\n",
        "print(\"Classification Report for SVM\")\n",
        "print(classification_rep1_svm)\n",
        "\n",
        "confusion1_svm = confusion_matrix(y1_test,y1_pred_svm)\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Confusion Matrix for SVM \")\n",
        "sns.heatmap(confusion1_svm, annot=True, fmt=\"d\", cmap=\"Reds\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "fprn, tprn, thresholds = roc_curve(y1_test,y1_pred_svm)\n",
        "roc_auc = auc(fprn, tprn)\n",
        "plt.figure()\n",
        "plt.plot(fprn, tprn, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "#plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAJChRcks5VG"
      },
      "source": [
        "## 5.3 FULLY CONNECTED NEURAL NETWORKS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.1 BASIC FULLY CONNECTED NEURAL NETWORK"
      ],
      "metadata": {
        "id": "iix2gAY8bj5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Create an instance of the OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Reshape your training and testing data\n",
        "y1_train_encoded = encoder.fit_transform(y1_train.reshape(-1, 1))\n",
        "y1_test_encoded = encoder.transform(y1_test.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "pCGEV5Vs5o16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/"
      ],
      "metadata": {
        "id": "yofC5rqlWfO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit/"
      ],
      "metadata": {
        "id": "bV0p2KSS9OW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXkGhrxPzkzx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"dnn/best_weights1.hdf5\", verbose=0, save_best_only=True) # save best model\n",
        "\n",
        "for i in range(5):\n",
        "  Nmodel = Sequential()\n",
        "  Nmodel.add(Dense(64, activation='relu'))\n",
        "  Nmodel.add(Dense(32, activation='relu'))\n",
        "  Nmodel.add(Dense(16, activation='relu'))\n",
        "  Nmodel.add(Dense(4, activation='relu'))\n",
        "  Nmodel.add(Dense(2, activation='softmax')) # Output\n",
        "\n",
        "  Nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "  monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience = 5, verbose = 2, mode = 'auto')\n",
        "\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "  Nmodel.fit(x1_train, y1_train_encoded, validation_data=(x1_test, y1_test_encoded),\n",
        "               callbacks=[monitor, checkpointer, TensorBoard(log_dir=log_dir, histogram_freq=1)],\n",
        "               verbose=1, epochs=1000)\n",
        "\n",
        "Nmodel.load_weights(\"dnn/best_weights1.hdf5\")\n",
        "\n",
        "y1_pred_prob1 = Nmodel.predict(x1_test)\n",
        "\n",
        "# Convert predicted probabilities to binary labels\n",
        "y1_pred1 = np.argmax(y1_pred_prob1, axis=1)\n",
        "\n",
        "# Convert one-hot encoded test labels to binary labels\n",
        "y1_true1 = np.argmax(y1_test_encoded, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "classification_rep1_fncc1 = classification_report(y1_true1, y1_pred1)\n",
        "print(\"Classification Report for FCNN:\\n\")\n",
        "print(classification_rep1_fncc1)\n",
        "\n",
        "# Confusion Matrix\n",
        "confusion1_fncc1 = confusion_matrix(y1_true1, y1_pred1)\n",
        "plt.figure()\n",
        "plt.imshow(confusion1_fncc1, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
        "plt.title('Confusion Matrix for FCNN')\n",
        "sns.heatmap(confusion1_fncc1, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y1_true1, y1_pred1)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "#plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DMcBTGfs-9xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.2 FULLY CONNECTED NEURAL NETWORK (RELU AND ADAM)"
      ],
      "metadata": {
        "id": "rVVhUXMubs6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "id": "EHJR5MfiQPVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/"
      ],
      "metadata": {
        "id": "R9bofh4H5BSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit/"
      ],
      "metadata": {
        "id": "uh9MTZRw5KFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"dnn/best_weights2.hdf5\", verbose=0, save_best_only=True) # save best model\n",
        "\n",
        "def build_model2(hp):\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  # Tune the number of hidden layers and units per layer\n",
        "  for i in range(hp.Int('num_layers', min_value=1, max_value=6)):\n",
        "\n",
        "    model.add(Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32), activation='relu'))\n",
        "\n",
        "    # Output layer with softmax activation\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Tune the learning rate\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    # Compile the model with the tuned learning rate and Adam optimizer\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model2,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        ")\n",
        "\n",
        "tuner.search(x1_train, y1_train_encoded, epochs=10, validation_data=(x1_test, y1_test_encoded),\n",
        "             callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Print the optimal combination of hyperparameters\n",
        "print(\"Optimal Hyperparameters:\")\n",
        "print(f\"Number of Hidden Layers: {best_hps.get('num_layers')}\")\n",
        "for i in range(best_hps.get('num_layers')):\n",
        "    units_key = 'units_' + str(i)\n",
        "    if units_key in best_hps:\n",
        "        print(f\"Layer {i + 1} - Units: {best_hps.get(units_key)}\")\n",
        "print(f\"Learning Rate: {best_hps.get('learning_rate')}\")\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience = 5, verbose = 2, mode = 'auto')\n",
        "\n",
        "# Build the final model with the best hyperparameters\n",
        "final_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the final model with the best hyperparameters\n",
        "final_model.fit(x1_train, y1_train_encoded, validation_data=(x1_test, y1_test_encoded),\n",
        "                 callbacks=[monitor, checkpointer, TensorBoard(log_dir=log_dir, histogram_freq=1)],\n",
        "                 verbose=2, epochs=1000)\n",
        "\n",
        "# Load the best weights\n",
        "final_model.load_weights(\"dnn/best_weights2.hdf5\")\n",
        "\n",
        "# Make predictions on the test data\n",
        "y1_pred_prob2 = final_model.predict(x1_test)\n",
        "\n",
        "# Convert predicted probabilities to binary labels\n",
        "y1_pred2 = np.argmax(y1_pred_prob2, axis=1)\n",
        "\n",
        "# Convert one-hot encoded test labels to binary labels\n",
        "y1_true2 = np.argmax(y1_test_encoded, axis=1)\n"
      ],
      "metadata": {
        "id": "_SS4DOSqOCcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "classification_rep1_fncc2 = classification_report(y1_true2, y1_pred2)\n",
        "print(\"Classification Report for FCNN:\\n\")\n",
        "print(classification_rep1_fncc2)\n",
        "\n",
        "# Confusion Matrix\n",
        "confusion1_fncc2 = confusion_matrix(y1_true2, y1_pred2)\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(confusion1_fncc2, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
        "plt.title('Confusion Matrix for FCNN (RELU & ADAM)')\n",
        "sns.heatmap(confusion1_fncc2, annot=True, fmt=\"d\", cmap=\"Reds\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y1_true2, y1_pred2)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hYzNq14WVcml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.3 FULLY CONNECTED NEURAL NETWORK (TANH AND SGD)"
      ],
      "metadata": {
        "id": "ztqmSJiAcE0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/"
      ],
      "metadata": {
        "id": "pJ4Ql1876EyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit/"
      ],
      "metadata": {
        "id": "QrVPILLS6AEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Define the best weights checkpoint\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=\"dnn/best_weights3.hdf5\", verbose=0, save_best_only=True)\n",
        "\n",
        "# Define the model architecture without specifying hyperparameters\n",
        "def build_model_sgd_tanh(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Tune the number of hidden layers and units per layer\n",
        "    for i in range(hp.Int('num_layers', min_value=1, max_value=12)):\n",
        "        model.add(Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
        "                        activation='tanh'))  # Change activation to 'tanh'\n",
        "\n",
        "    # Output layer with softmax activation\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Define optimizer as SGD with tunable learning rate\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner_sgd_tanh = kt.BayesianOptimization(\n",
        "    build_model_sgd_tanh,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    #directory=\"keras_tuner_sgd_tanh\",\n",
        "    overwrite=True,\n",
        ")\n",
        "\n",
        "tuner_sgd_tanh.search(x1_train, y1_train_encoded, epochs=10, validation_data=(x1_test, y1_test_encoded),\n",
        "                      callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "best_hps_sgd_tanh = tuner_sgd_tanh.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Print the optimal combination of hyperparameters for SGD and tanh\n",
        "print(\"Optimal Hyperparameters for SGD and tanh:\")\n",
        "print(f\"Number of Hidden Layers: {best_hps_sgd_tanh.get('num_layers')}\")\n",
        "for i in range(best_hps_sgd_tanh.get('num_layers')):\n",
        "    units_key = 'units_' + str(i)\n",
        "    if units_key in best_hps_sgd_tanh:\n",
        "        print(f\"Layer {i + 1} - Units: {best_hps_sgd_tanh.get(units_key)}\")\n",
        "print(f\"Learning Rate: {best_hps_sgd_tanh.get('learning_rate')}\")\n",
        "\n",
        "# Build the final model with the best hyperparameters for SGD and tanh\n",
        "final_model_sgd_tanh = tuner_sgd_tanh.hypermodel.build(best_hps_sgd_tanh)\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience = 5, verbose = 2, mode = 'auto')\n",
        "\n",
        "# Train the final model with the best hyperparameters for SGD and tanh\n",
        "final_model_sgd_tanh.fit(x1_train, y1_train_encoded, validation_data=(x1_test, y1_test_encoded),\n",
        "                         callbacks=[monitor, checkpointer, tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)],\n",
        "                         verbose=1, epochs=100)\n",
        "\n",
        "# Load the best weights\n",
        "final_model_sgd_tanh.load_weights(\"dnn/best_weights3.hdf5\")\n",
        "\n",
        "# Make predictions on the test data\n",
        "y1_pred_prob_sgd_tanh = final_model_sgd_tanh.predict(x1_test)\n",
        "\n",
        "# Convert predicted probabilities to binary labels\n",
        "y1_pred_sgd_tanh = np.argmax(y1_pred_prob_sgd_tanh, axis=1)\n",
        "\n",
        "# Convert one-hot encoded test labels to binary labels\n",
        "y1_true_sgd_tanh = np.argmax(y1_test_encoded, axis=1)\n"
      ],
      "metadata": {
        "id": "-L_XWxpTcKxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "classification_rep1_fncc3 = classification_report(y1_true_sgd_tanh, y1_pred_sgd_tanh)\n",
        "print(\"Classification Report for FCNN:\\n\")\n",
        "print(classification_rep1_fncc3)\n",
        "\n",
        "# Confusion Matrix\n",
        "confusion1_fncc3 = confusion_matrix(y1_true_sgd_tanh, y1_pred_sgd_tanh)\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(confusion1_fncc3, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
        "plt.title('Confusion Matrix for FCNN (TANH & SGD)')\n",
        "sns.heatmap(confusion1_fncc3, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y1_true_sgd_tanh, y1_pred_sgd_tanh)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lkdp9u-EcK6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.4 FULLY CONNECTED NEURAL NETWORK (RELU AND SGD)"
      ],
      "metadata": {
        "id": "5RQr1OAW8md0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/"
      ],
      "metadata": {
        "id": "9tPWZ6FD8thv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit/"
      ],
      "metadata": {
        "id": "wMMurv6U8zP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Define the best weights checkpoint\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=\"dnn/best_weights4.hdf5\", verbose=0, save_best_only=True)\n",
        "\n",
        "# Define the model architecture without specifying hyperparameters\n",
        "def build_model_relu_sgd(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Tune the number of hidden layers and units per layer\n",
        "    for i in range(hp.Int('num_layers', min_value=1, max_value=16)):\n",
        "        model.add(Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
        "                        activation='relu'))  # Change activation to 'relu'\n",
        "\n",
        "    # Output layer with softmax activation\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Define optimizer as SGD with tunable learning rate\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner_relu_sgd = kt.BayesianOptimization(\n",
        "    build_model_relu_sgd,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,\n",
        "    executions_per_trial=2,\n",
        "    overwrite=True,\n",
        ")\n",
        "\n",
        "tuner_relu_sgd.search(x1_train, y1_train_encoded, epochs=10, validation_data=(x1_test, y1_test_encoded),\n",
        "                      callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "best_hps_relu_sgd = tuner_relu_sgd.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Print the optimal combination of hyperparameters for ReLU and SGD\n",
        "print(\"Optimal Hyperparameters for ReLU and SGD:\")\n",
        "print(f\"Number of Hidden Layers: {best_hps_relu_sgd.get('num_layers')}\")\n",
        "for i in range(best_hps_relu_sgd.get('num_layers')):\n",
        "    units_key = 'units_' + str(i)\n",
        "    if units_key in best_hps_relu_sgd:\n",
        "        print(f\"Layer {i + 1} - Units: {best_hps_relu_sgd.get(units_key)}\")\n",
        "print(f\"Learning Rate: {best_hps_relu_sgd.get('learning_rate')}\")\n",
        "\n",
        "# Build the final model with the best hyperparameters for ReLU and SGD\n",
        "final_model_relu_sgd = tuner_relu_sgd.hypermodel.build(best_hps_relu_sgd)\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience = 5, verbose = 2, mode = 'auto')\n",
        "\n",
        "# Train the final model with the best hyperparameters for ReLU and SGD\n",
        "final_model_relu_sgd.fit(x1_train, y1_train_encoded, validation_data=(x1_test, y1_test_encoded),\n",
        "                         callbacks=[monitor, checkpointer, tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)],\n",
        "                         verbose=1, epochs=1000)\n",
        "\n",
        "# Load the best weights\n",
        "final_model_relu_sgd.load_weights(\"dnn/best_weights4.hdf5\")\n",
        "\n",
        "# Make predictions on the test data\n",
        "y1_pred_prob_relu_sgd = final_model_relu_sgd.predict(x1_test)\n",
        "\n",
        "# Convert predicted probabilities to binary labels\n",
        "y1_pred_relu_sgd = np.argmax(y1_pred_prob_relu_sgd, axis=1)\n",
        "\n",
        "# Convert one-hot encoded test labels to binary labels\n",
        "y1_true_relu_sgd = np.argmax(y1_test_encoded, axis=1)\n"
      ],
      "metadata": {
        "id": "qUk4dwmM9Aa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "classification_rep1_fncc4 = classification_report(y1_true_relu_sgd, y1_pred_relu_sgd)\n",
        "print(\"Classification Report for FCNN:\\n\")\n",
        "print(classification_rep1_fncc4)\n",
        "\n",
        "# Confusion Matrix\n",
        "confusion1_fncc4 = confusion_matrix(y1_true_relu_sgd, y1_pred_relu_sgd)\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(confusion1_fncc4, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
        "plt.title('Confusion Matrix for FCNN (RELU & SGD)')\n",
        "sns.heatmap(confusion1_fncc4, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y1_true_relu_sgd, y1_pred_relu_sgd)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CDgPkhuQ9nrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.5.5 FULLY CONNNECTED NEURAL NETWORK (TANH AND ADAM)"
      ],
      "metadata": {
        "id": "N04MtolY-IVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/"
      ],
      "metadata": {
        "id": "8xvBg_BS-WO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit/"
      ],
      "metadata": {
        "id": "p90BwkI0-ZRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=\"dnn/best_weights5.hdf5\", verbose=0, save_best_only=True)\n",
        "\n",
        "# Define the model architecture without specifying hyperparameters\n",
        "def build_model_tanh_adam(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Tune the number of hidden layers and units per layer\n",
        "    for i in range(hp.Int('num_layers', min_value=1, max_value=6)):\n",
        "        model.add(Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
        "                        activation='tanh'))  # Change activation to 'tanh'\n",
        "\n",
        "    # Output layer with softmax activation\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Define optimizer as ADAM with tunable learning rate\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner_tanh_adam = kt.BayesianOptimization(\n",
        "    build_model_tanh_adam,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,\n",
        "    executions_per_trial=3,\n",
        "    overwrite=True,\n",
        ")\n",
        "\n",
        "tuner_tanh_adam.search(x1_train, y1_train_encoded, epochs=10, validation_data=(x1_test, y1_test_encoded),\n",
        "                      callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "best_hps_tanh_adam = tuner_tanh_adam.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Print the optimal combination of hyperparameters for TANH and ADAM\n",
        "print(\"Optimal Hyperparameters for TANH and ADAM:\")\n",
        "print(f\"Number of Hidden Layers: {best_hps_tanh_adam.get('num_layers')}\")\n",
        "for i in range(best_hps_tanh_adam.get('num_layers')):\n",
        "    units_key = 'units_' + str(i)\n",
        "    if units_key in best_hps_tanh_adam:\n",
        "        print(f\"Layer {i + 1} - Units: {best_hps_tanh_adam.get(units_key)}\")\n",
        "print(f\"Learning Rate: {best_hps_tanh_adam.get('learning_rate')}\")\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience = 5, verbose = 2, mode = 'auto')\n",
        "\n",
        "# Build the final model with the best hyperparameters for TANH and ADAM\n",
        "final_model_tanh_adam = tuner_tanh_adam.hypermodel.build(best_hps_tanh_adam)\n",
        "\n",
        "# Train the final model with the best hyperparameters for TANH and ADAM\n",
        "final_model_tanh_adam.fit(x1_train, y1_train_encoded, validation_data=(x1_test, y1_test_encoded),\n",
        "                         callbacks=[monitor, checkpointer, tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)],\n",
        "                         verbose=1, epochs=1000)\n",
        "\n",
        "# Load the best weights\n",
        "final_model_tanh_adam.load_weights(\"dnn/best_weights5.hdf5\")\n",
        "\n",
        "# Make predictions on the test data\n",
        "y1_pred_prob_tanh_adam = final_model_tanh_adam.predict(x1_test)\n",
        "\n",
        "# Convert predicted probabilities to binary labels\n",
        "y1_pred_tanh_adam = np.argmax(y1_pred_prob_tanh_adam, axis=1)\n",
        "\n",
        "# Convert one-hot encoded test labels to binary labels\n",
        "y1_true_tanh_adam = np.argmax(y1_test_encoded, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "VzoREhv0-fef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "classification_rep1_fncc5 = classification_report(y1_true_tanh_adam, y1_pred_tanh_adam)\n",
        "print(\"Classification Report for FCNN:\\n\")\n",
        "print(classification_rep1_fncc5)\n",
        "\n",
        "# Confusion Matrix\n",
        "confusion1_fncc5 = confusion_matrix(y1_true_tanh_adam, y1_pred_tanh_adam)\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(confusion1_fncc5, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
        "plt.title('Confusion Matrix for FCNN (TANH & ADAM)')\n",
        "sns.heatmap(confusion1_fncc5, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y1_true_tanh_adam, y1_pred_tanh_adam)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MoyUbeVn-fjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9Bcx8-JkW0I"
      },
      "source": [
        "# 6.0 Additional Feature:Create a balanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEltZu-CwtrF"
      },
      "outputs": [],
      "source": [
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8yp5mTd6K1Z"
      },
      "source": [
        "## 6.1 OVERSAMPLING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv6ezS3J6KHL"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyJoRA2o6Tck"
      },
      "outputs": [],
      "source": [
        "x=df.drop([\"target\"],axis=1)\n",
        "y=df.target\n",
        "print (Counter(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txOiMwYb7Am9"
      },
      "outputs": [],
      "source": [
        "RS=RandomOverSampler()\n",
        "XRS,YRS=RS.fit_resample(x,y)\n",
        "print (Counter(YRS))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch0PSRy-rCtC"
      },
      "source": [
        "### 6.1.1 NORMALIZING NUMERIC FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCRceq6i-gyJ"
      },
      "outputs": [],
      "source": [
        "xn = zscore(XRS)\n",
        "xn.shape\n",
        "xn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvwnFe5QxEE9"
      },
      "outputs": [],
      "source": [
        "x_numpy=xn.to_numpy()\n",
        "y_numpy =YRS.to_numpy()\n",
        "x_numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqxXgUZfkrx0"
      },
      "source": [
        "## 6.2 TRAIN/TEST SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIQqWAPwKZW5"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_numpy, y_numpy, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMUjl93Dmptb"
      },
      "source": [
        "## 6.3 MODEL SELECTION AFTER OVERSAMPLING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiUbXOFEHU82"
      },
      "source": [
        "### 6.3.1 KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jU0h2ImoNmWw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "k = 5\n",
        "\n",
        "# Create a k-NN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "knn_classifier.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_knn2 = knn_classifier.predict(x_test)\n",
        "\n",
        "# Display classification report for k-NN\n",
        "classification_rep2_knn = classification_report(y_test, y_pred_knn2)\n",
        "print(\"Classification Report for k-NN (5):\")\n",
        "print(classification_rep2_knn)\n",
        "\n",
        "# Plot confusion matrix for k-NN\n",
        "confusion2_knn = confusion_matrix(y_test, y_pred_knn2)\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"k-NN (5) After Oversampling\")\n",
        "sns.heatmap(confusion2_knn, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC curve for k-NN\n",
        "fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, y_pred_knn2)\n",
        "roc_auc_knn = roc_auc_score(y_test, y_pred_knn2)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr_knn, tpr_knn, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWmZtv2kHk2F"
      },
      "source": [
        "### 6.3.2 SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHTd-o8PO4yP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "svm_classifier = SVC(kernel='poly')\n",
        "\n",
        "svm_classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred_svm2 = svm_classifier.predict(x_test)\n",
        "\n",
        "# Display classification report for SVM\n",
        "classification_rep2_svm = classification_report(y_test, y_pred_svm2)\n",
        "print(\"Classification Report for SVM:\")\n",
        "print(classification_rep2_svm)\n",
        "\n",
        "# Plot confusion matrix for SVM\n",
        "confusion2_svm = confusion_matrix(y_test, y_pred_svm2)\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.title(\"SVM after oversampling\")\n",
        "sns.heatmap(confusion2_svm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC curve for\n",
        "fpr_svm, tpr_svm, thresholds_svm = roc_curve(y_test, y_pred_svm2)\n",
        "roc_auc_svm = roc_auc_score(y_test, y_pred_svm2)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr_svm, tpr_svm, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWlA82IcPQZ7"
      },
      "source": [
        "### 6.3.3 FULLY CONNECTED NEURAL NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhyKWSzdQion"
      },
      "outputs": [],
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit/"
      ],
      "metadata": {
        "id": "pWw6weGREjZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape your training and testing labels if they are 1D arrays\n",
        "y_train_encoded = encoder.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test_encoded = encoder.transform(y_test.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "hyM-CYIDFF66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=\"dnn/best_weights6.hdf5\", verbose=0, save_best_only=True)\n",
        "\n",
        "# Define the model architecture without specifying hyperparameters\n",
        "def build_model_tanh_adam2(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Tune the number of hidden layers and units per layer\n",
        "    for i in range(hp.Int('num_layers', min_value=1, max_value=16)):\n",
        "        model.add(Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
        "                        activation='tanh'))  # Change activation to 'tanh'\n",
        "\n",
        "    # Output layer with softmax activation\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Define optimizer as ADAM with tunable learning rate\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner_tanh_adam = kt.BayesianOptimization(\n",
        "    build_model_tanh_adam2,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        ")\n",
        "\n",
        "tuner_tanh_adam.search(x_train, y_train_encoded, epochs=10, validation_data=(x_test, y_test_encoded),\n",
        "                      callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "best_hps_tanh_adam = tuner_tanh_adam.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Print the optimal combination of hyperparameters for TANH and ADAM\n",
        "print(\"Optimal Hyperparameters for TANH and ADAM:\")\n",
        "print(f\"Number of Hidden Layers: {best_hps_tanh_adam.get('num_layers')}\")\n",
        "for i in range(best_hps_tanh_adam.get('num_layers')):\n",
        "    units_key = 'units_' + str(i)\n",
        "    if units_key in best_hps_tanh_adam:\n",
        "        print(f\"Layer {i + 1} - Units: {best_hps_tanh_adam.get(units_key)}\")\n",
        "print(f\"Learning Rate: {best_hps_tanh_adam.get('learning_rate')}\")\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience = 5, verbose = 2, mode = 'auto')\n",
        "\n",
        "# Build the final model with the best hyperparameters for TANH and ADAM\n",
        "final_model_tanh_adam = tuner_tanh_adam.hypermodel.build(best_hps_tanh_adam)\n",
        "\n",
        "# Train the final model with the best hyperparameters for TANH and ADAM\n",
        "final_model_tanh_adam.fit(x_train, y_train_encoded, validation_data=(x_test, y_test_encoded),\n",
        "                         callbacks=[monitor, checkpointer, tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)],\n",
        "                         verbose=1, epochs=1000)\n",
        "\n",
        "# Load the best weights\n",
        "final_model_tanh_adam.load_weights(\"dnn/best_weights6.hdf5\")\n",
        "\n",
        "# Make predictions on the test data\n",
        "y1_pred_prob_tanh_adam2 = final_model_tanh_adam.predict(x_test)\n",
        "\n",
        "# Convert predicted probabilities to binary labels\n",
        "y1_pred_tanh_adam2 = np.argmax(y1_pred_prob_tanh_adam, axis=1)\n",
        "\n",
        "# Convert one-hot encoded test labels to binary labels\n",
        "y1_true_tanh_adam2 = np.argmax(y1_test_encoded, axis=1)\n"
      ],
      "metadata": {
        "id": "DCzRpkE2EjcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "classification_rep1_fncc6 = classification_report(y1_true_tanh_adam2, y1_pred_tanh_adam2)\n",
        "print(\"Classification Report for FCNN:\\n\")\n",
        "print(classification_rep1_fncc6)\n",
        "\n",
        "# Confusion Matrix\n",
        "confusion1_fncc6 = confusion_matrix(y1_true_tanh_adam2, y1_pred_tanh_adam2)\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(confusion1_fncc6, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
        "plt.title('FCNN after Oversampling')\n",
        "sns.heatmap(confusion1_fncc6, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y1_true_tanh_adam2, y1_pred_tanh_adam2)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "#plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GpWwvd23Ejfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsDy-RhL7sS_"
      },
      "source": [
        "# 7.0 Additional Feature: Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 Lasso Model"
      ],
      "metadata": {
        "id": "XDteX0RCa7th"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IH541g8JpAWJ"
      },
      "outputs": [],
      "source": [
        "# Create a Logistic Regression model with L1 regularization (Lasso)\n",
        "lasso_model = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, random_state=84)\n",
        "\n",
        "# Fit the model on your data\n",
        "lasso_model.fit(x_train, y_train)\n",
        "\n",
        "# Get the coefficients (weights) of the features\n",
        "feature_weights = lasso_model.coef_\n",
        "\n",
        "# Use SelectFromModel to perform feature selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "feature_selector = SelectFromModel(lasso_model, prefit=True)\n",
        "\n",
        "# Transform the training and test data to select important features\n",
        "x_train_selected = feature_selector.transform(x_train)\n",
        "x_test_selected = feature_selector.transform(x_test)\n",
        "\n",
        "# Get the absolute feature weights and their indices\n",
        "absolute_weights = np.abs(feature_weights)\n",
        "sorted_feature_indices = np.argsort(absolute_weights[0])[::-1]  # Sort in descending order\n",
        "\n",
        "# Select the top 5 feature indices\n",
        "top_5_feature_indices = sorted_feature_indices[:5]\n",
        "\n",
        "# Create NumPy ndarrays with only the top 5 selected features\n",
        "x_train_top_5_features = x_train[:, top_5_feature_indices]\n",
        "x_test_top_5_features = x_test[:, top_5_feature_indices]\n",
        "\n",
        "# Print the selected top 5 feature indices\n",
        "print(\"Selected Top 5 Feature Indices:\", top_5_feature_indices)\n",
        "\n",
        "# Print the corresponding feature weights for the top 5 features\n",
        "print(\"Feature Weights (Coefficients) for Top 5 Features:\")\n",
        "for index, weight in zip(top_5_feature_indices, feature_weights[0][top_5_feature_indices]):\n",
        "    print(f\"Feature {index}: {weight:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKXMrFqqYjW3"
      },
      "source": [
        "### 7.2 Knn with top 5 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU8EK5bLpuqe"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "k = 5\n",
        "\n",
        "# Create a k-NN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "knn_classifier.fit(x_train_top_5_features, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_knn3 = knn_classifier.predict(x_test_top_5_features)\n",
        "\n",
        "# Display classification report for k-NN\n",
        "classification_rep3_knn = classification_report(y_test, y_pred_knn3)\n",
        "print(\"Classification Report for k-NN (5):\")\n",
        "print(classification_rep2_knn)\n",
        "\n",
        "# Plot confusion matrix for k-NN\n",
        "confusion3_knn = confusion_matrix(y_test, y_pred_knn3)\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"k-NN with top 5 features\")\n",
        "sns.heatmap(confusion3_knn, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC curve for k-NN\n",
        "fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, y_pred_knn3)\n",
        "roc_auc_knn = roc_auc_score(y_test, y_pred_knn2)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr_knn, tpr_knn, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "#plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ7BuUBqYils"
      },
      "source": [
        "### 7.3 SVM with top 5 features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "svm_classifier = SVC(kernel='poly')\n",
        "\n",
        "svm_classifier.fit(x_train_top_5_features, y_train)\n",
        "\n",
        "y_pred_svm3 = svm_classifier.predict(x_test_top_5_features)\n",
        "\n",
        "# Display classification report for SVM\n",
        "classification_rep3_svm = classification_report(y_test, y_pred_svm3)\n",
        "print(\"Classification Report for SVM:\")\n",
        "print(classification_rep3_svm)\n",
        "\n",
        "# Plot confusion matrix for SVM\n",
        "confusion3_svm = confusion_matrix(y_test, y_pred_svm3)\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"SVM with top 5 features\")\n",
        "sns.heatmap(confusion3_svm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC curve for\n",
        "fpr_svm3, tpr_svm3, thresholds_svm3 = roc_curve(y_test, y_pred_svm3)\n",
        "roc_auc_svm3 = roc_auc_score(y_test, y_pred_svm3)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr_svm3, tpr_svm3, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "#plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2Shy1mRcYm1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu2YtZwC9dRo"
      },
      "source": [
        "### 7.4 Fully connected neural network with top 5 features\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/"
      ],
      "metadata": {
        "id": "17xJ361JYmK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit/"
      ],
      "metadata": {
        "id": "e9QnrWn3J9Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=\"dnn/best_weights7.hdf5\", verbose=0, save_best_only=True)\n",
        "\n",
        "# Define the model architecture without specifying hyperparameters\n",
        "def build_model_tanh_adam3(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Input(shape=(5,)))\n",
        "\n",
        "    # Tune the number of hidden layers and units per layer\n",
        "    for i in range(hp.Int('num_layers', min_value=1, max_value=16)):\n",
        "        model.add(Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
        "                        activation='tanh'))  # Change activation to 'tanh'\n",
        "\n",
        "    # Output layer with softmax activation\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Define optimizer as ADAM with tunable learning rate\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner_tanh_adam = kt.BayesianOptimization(\n",
        "    build_model_tanh_adam3,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        ")\n",
        "\n",
        "tuner_tanh_adam.search(x_train_top_5_features, y_train_encoded, epochs=10, validation_data=(x_test_top_5_features, y_test_encoded),\n",
        "                      callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "best_hps_tanh_adam = tuner_tanh_adam.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Print the optimal combination of hyperparameters for TANH and ADAM\n",
        "print(\"Optimal Hyperparameters for TANH and ADAM:\")\n",
        "print(f\"Number of Hidden Layers: {best_hps_tanh_adam.get('num_layers')}\")\n",
        "for i in range(best_hps_tanh_adam.get('num_layers')):\n",
        "    units_key = 'units_' + str(i)\n",
        "    if units_key in best_hps_tanh_adam:\n",
        "        print(f\"Layer {i + 1} - Units: {best_hps_tanh_adam.get(units_key)}\")\n",
        "print(f\"Learning Rate: {best_hps_tanh_adam.get('learning_rate')}\")\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience = 5, verbose = 2, mode = 'auto')\n",
        "\n",
        "# Build the final model with the best hyperparameters for TANH and ADAM\n",
        "final_model_tanh_adam = tuner_tanh_adam.hypermodel.build(best_hps_tanh_adam)\n",
        "\n",
        "# Train the final model with the best hyperparameters for TANH and ADAM\n",
        "final_model_tanh_adam.fit(x_train_top_5_features, y_train_encoded, validation_data=(x_test_top_5_features, y_test_encoded),\n",
        "                         callbacks=[checkpointer, tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1), tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)],\n",
        "                         verbose=1, epochs=1000)\n",
        "\n",
        "# Load the best weights\n",
        "final_model_tanh_adam.load_weights(\"dnn/best_weights7.hdf5\")\n",
        "\n",
        "# Make predictions on the test data\n",
        "y1_pred_prob_tanh_adam3 = final_model_tanh_adam.predict(x_test_top_5_features)\n",
        "\n",
        "# Convert predicted probabilities to binary labels\n",
        "y1_pred_tanh_adam3 = np.argmax(y1_pred_prob_tanh_adam, axis=1)\n",
        "\n",
        "# Convert one-hot encoded test labels to binary labels\n",
        "y1_true_tanh_adam3 = np.argmax(y1_test_encoded, axis=1)\n"
      ],
      "metadata": {
        "id": "RG7XfQxhGCm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "classification_rep1_fncc7 = classification_report(y1_true_tanh_adam3, y1_pred_tanh_adam3)\n",
        "print(\"Classification Report for FCNN:\\n\")\n",
        "print(classification_rep1_fncc7)\n",
        "\n",
        "# Confusion Matrix\n",
        "confusion1_fncc7 = confusion_matrix(y1_true_tanh_adam3, y1_pred_tanh_adam3)\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(confusion1_fncc7, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
        "plt.title('FCNN with top 5 features')\n",
        "sns.heatmap(confusion1_fncc7, annot=True, fmt=\"d\", cmap=\"Reds\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y1_true_tanh_adam3, y1_pred_tanh_adam3)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "#plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HsW3Z2FeGC4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5fCExKJMW0e"
      },
      "source": [
        "# 8.0 Additional Feature: *K Means*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnKkz0vjMwFz"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Fit K-means clustering on the training data\n",
        "kmeans = KMeans(n_clusters=2, random_state=84)\n",
        "kmeans.fit(x_train_top_5_features)\n",
        "\n",
        "test_cluster_labels = kmeans.predict(x_test_top_5_features)\n",
        "\n",
        "# Calculate cluster centroids\n",
        "cluster_centers = kmeans.cluster_centers_\n",
        "\n",
        "# Assign labels based on majority class in each cluster\n",
        "cluster_labels = []\n",
        "for cluster_id in range(2):\n",
        "    cluster_indices = (test_cluster_labels == cluster_id)\n",
        "    cluster_majority_label = np.argmax(np.bincount(y_test[cluster_indices]))\n",
        "    cluster_labels.append(cluster_majority_label)\n",
        "\n",
        "# Assign labels to the test data based on the closest centroid\n",
        "predicted_labels = [cluster_labels[cluster_id] for cluster_id in test_cluster_labels]\n",
        "\n",
        "# Calculate confusion matrix\n",
        "confusion_kmeans = confusion_matrix(y_test, predicted_labels)\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Confusion Matrix for K-means Clustering\")\n",
        "sns.heatmap(confusion_kmeans, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Calculate classification report for K-means Clustering\n",
        "classification_rep_kmeans = classification_report(y_test, predicted_labels)\n",
        "print(\"Classification Report for K-means Clustering:\")\n",
        "print(classification_rep_kmeans)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Fit K-means clustering on the training data\n",
        "kmeans = KMeans(n_clusters=2, random_state=84)\n",
        "kmeans.fit(x_train)\n",
        "\n",
        "test_cluster_labels = kmeans.predict(x_test)\n",
        "\n",
        "# Calculate cluster centroids\n",
        "cluster_centers = kmeans.cluster_centers_\n",
        "\n",
        "# Assign labels based on majority class in each cluster\n",
        "cluster_labels = []\n",
        "for cluster_id in range(2):\n",
        "    cluster_indices = (test_cluster_labels == cluster_id)\n",
        "    cluster_majority_label = np.argmax(np.bincount(y_test[cluster_indices]))\n",
        "    cluster_labels.append(cluster_majority_label)\n",
        "\n",
        "# Assign labels to the test data based on the closest centroid\n",
        "predicted_labels = [cluster_labels[cluster_id] for cluster_id in test_cluster_labels]\n",
        "\n",
        "# Calculate confusion matrix\n",
        "confusion_kmeans = confusion_matrix(y_test, predicted_labels)\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Confusion Matrix for K-means Clustering\")\n",
        "sns.heatmap(confusion_kmeans, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Calculate classification report for K-means Clustering\n",
        "classification_rep_kmeans = classification_report(y_test, predicted_labels)\n",
        "print(\"Classification Report for K-means Clustering:\")\n",
        "print(classification_rep_kmeans)"
      ],
      "metadata": {
        "id": "wiBbKW6Yu7Fx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VB0Wg35XRpfT",
        "T20lTqI4RtVL",
        "0G8uPuhJRxKQ",
        "_rvL8qteO75d",
        "0SNQG61ykLSn",
        "5OfRdcukkQH_",
        "PpnH0hsqT_hF",
        "dzqC40UnUi9C",
        "9Qv-YZxCXMnp",
        "t8yp5mTd6K1Z"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}